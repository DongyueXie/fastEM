---
title: "Accelerating co-ordinate ascent updates for linear regression using DAAREM"
date: June 4, 2019
site: workflowr::wflow_site
output: workflowr::wflow_html
---

In this small demonstration, we show how the
[DAAREM method][daarem-paper] can be used to accelerate a very simple
co-ordinate ascent algorithm for computing the *maximum a posteriori*
estimate of the coefficients in a linear regression with a simple
normal prior on the coefficients (*i.e.*, ridge regression).

```{r knitr, echo=FALSE}
knitr::opts_chunk$set(comment = "#",results = "hold",collapse = TRUE,
                      fig.align = "center")
```

## Analysis settings

These variables specify how the data are generated: `n` is the number
of simulated samples, `p` is the number of simulated predictors, `na`
is the number of simulated predictors that have a nonzero effect, `se`
is the variance of the residual.

```{r sim-settings}
n  <- 200 
p  <- 500
na <- 10
se <- 2
```

This specifies the prior on the regression coefficients: it is normal
with zero mean and standard deviation `s0`.

```{r model-settings}
s0 <- 1/se
```

## Set up environment

Load some packages and function definitions used in the example below.

```{r load-pkgs, warning=FALSE, message=FALSE}
library(MASS)
library(daarem)
library(ggplot2)
library(cowplot)
source("../code/misc.R")
source("../code/datasim.R")
source("../code/ridge.R")
```

Initialize the sequence of pseudorandom numbers.

```{set-seed}
set.seed(1)
```

## Simulate data

Simulate predictors with "decaying" correlations.

```{r sim-x}
X <- simulate_predictors_decaying_corr(n,p,s = 0.5)
X <- scale(X,center = TRUE,scale = FALSE)
```

Generate additive effects for the markers so that exactly `na` of them have
a nonzero effect on the trait.

```{r sim-beta}
i    <- sample(p,na)
b    <- rep(0,p)
b[i] <- rnorm(na)
```

Simulate the continuous outcomes, and center them.

```{r sim-y}
y <- drop(X %*% b + se*rnorm(n))
y <- y - mean(y)
```

## Run basic co-ordinate ascent updates

Set the initial estimate of the coefficients.

```{r init-estimate}
b0 <- rep(0,p)
```

Fit the ridge regression model by running 100 iterations of the basic
co-ordinate ascent updates. Note that the co-ordinate ascent updates
are very simple, and are easily implemented in a single line of R
code; see the code for the `ridge.update` function.

```{r fit-ridge}
out <- system.time(fit1 <- ridge(X,y,b0,s0,numiter = 100))
f1  <- ridge.objective(X,y,fit1$b,s0)
cat(sprintf("Computation took %0.2f seconds.\n",out["elapsed"]))
cat(sprintf("Objective value at solution is %0.12f.\n",f1))
```

## Run accelerated co-ordinate ascent updates

Fit the ridge regression model again, this time using DAAREM to speed
up the co-ordinate ascent algorithm.

```{r fit-ridge-2}
out <- system.time(fit2 <- daarridge(X,y,b0,s0,numiter = 100))
f2  <- ridge.objective(X,y,fit2$b,s0)
cat(sprintf("Computation took %0.2f seconds.\n",out["elapsed"]))
cat(sprintf("Objective value at solution is %0.12f.\n",f2))
```

We see that the DAAREM solution is better (it has a higher posterior
value).

## Plot improvement in solution over time

Since the ridge estimate as a closed-form solution, we can easily
compare the above estimates obtained via co-ordinate ascent against
the actual solution.

```{r ridge-solution}
bhat <- drop(solve(t(X) %*% X + diag(rep(1/s0^2,p)),t(X) %*% y))
f    <- ridge.objective(X,y,bhat,s0)
```

This plot shows the improvement in the solution over time for the two
co-ordinate ascent algorithms: the vertical axis ("distance to best
solution") shows the difference between the largest log-posterior
obtained, and the log-posterior at the actual ridge solution (`bhat`).

```{r plot-iter-vs-objective, fig.height=4, fig.width=6}
pdat <-
  rbind(data.frame(iter = 1:100,dist = f - fit1$value,method = "basic"),
        data.frame(iter = 1:100,dist = f - fit2$value,method = "accelerated"))
p <- ggplot(pdat,aes(x = iter,y = dist,col = method)) +
  geom_line(size = 1) +
  scale_y_continuous(trans = "log10",breaks = 10^seq(-8,4)) +
  scale_color_manual(values = c("darkorange","dodgerblue")) +
  labs(x = "iteration",y = "distance from solution")
print(p)
```

From this plot, we see that the accelerated algorithm progresses much
more rapidly toward the solution; after 100 iterations, it nearly
recovers the actual ridge estimates, whereas the unaccelerated version
is still very far away.

[daarem-paper]: https://doi.org/10.1080/10618600.2019.1594835
